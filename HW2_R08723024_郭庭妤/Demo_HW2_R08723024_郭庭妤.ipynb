{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 題目\n",
    "### Use LSTM & CNN model to classify MNIST dataset with at least 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一、程式碼\n",
    "* 所有檔案: mnist_lstm_R08723024_郭庭妤.py、mnist_cnn_R08723024_郭庭妤.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. mnist_lstm_R08723024_郭庭妤.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes):\n",
    "    x_train = x_train.reshape(-1, n_step, n_input)\n",
    "    x_test = x_test.reshape(-1, n_step, n_input)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, n_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, n_classes)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def lstm_model(n_input, n_step, n_hidden, n_classes):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_hidden, batch_input_shape=(None, n_step, n_input), unroll=True))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "def mnist_lstm_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 128\n",
    "\n",
    "    # model parameters\n",
    "    n_input = 28\n",
    "    n_step = 28\n",
    "    n_hidden = 256\n",
    "    n_classes = 10\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = lstm_preprocess(x_train, x_test, y_train, y_test, n_step, n_input, n_classes)\n",
    "\n",
    "    model = lstm_model(n_input, n_step, n_hidden, n_classes)\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('LSTM test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. mnist_cnn_R08723024_郭庭妤.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import keras\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def cnn_preprocess(x_train, x_test, y_train, y_test):\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "    return (x_train, x_test, y_train, y_test)\n",
    "\n",
    "\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n",
    "    model.add(MaxPool2D(strides=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(84, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "def trainning(model, x_train, y_train, x_test, y_test, \n",
    "              learning_rate, training_iters, batch_size):\n",
    "    adam = Adam(lr=learning_rate)\n",
    "    model.summary()\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size, epochs=training_iters,\n",
    "              verbose=1, validation_data=(x_test, y_test))\n",
    "\n",
    "def print_confusion_result(x_train, x_test, y_train, y_test, model):\n",
    "    # get train & test predictions\n",
    "    train_pred = model.predict_classes(x_train)\n",
    "    test_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    # get train & test true labels\n",
    "    train_label = y_train\n",
    "    test_label =  y_test\n",
    "    \n",
    "    # confusion matrix\n",
    "    train_result_cm = confusion_matrix(train_label, train_pred, labels=range(10))\n",
    "    test_result_cm = confusion_matrix(test_label, test_pred, labels=range(10))\n",
    "    print(train_result_cm, '\\n'*2, test_result_cm)\n",
    "\n",
    "\n",
    "\n",
    "def mnist_cnn_main():\n",
    "    # training parameters\n",
    "    learning_rate = 0.001\n",
    "    training_iters = 1\n",
    "    batch_size = 64\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test, y_train_o, y_test_o = cnn_preprocess(x_train, x_test, y_train, y_test)\n",
    "\n",
    "    model = cnn_model()\n",
    "    trainning(model, x_train, y_train_o, x_test, y_test_o, learning_rate, training_iters, batch_size)\n",
    "    scores = model.evaluate(x_test, y_test_o, verbose=0)\n",
    "    print('CNN test accuracy:', scores[1])\n",
    "    print_confusion_result(x_train, x_test, y_train, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二、執行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LSTM\n",
    "* Accuracy: 0.9560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 256)               291840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 294,410\n",
      "Trainable params: 294,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.4525 - accuracy: 0.8487 - val_loss: 0.1395 - val_accuracy: 0.9560\n",
      "LSTM test accuracy: 0.9559999704360962\n",
      "[[5710    2   31   13    8   47   63    1   29   19]\n",
      " [   2 6629   25   36    8    6    7   22    4    3]\n",
      " [   9   19 5744   49   15   14   24   60   21    3]\n",
      " [   3   20   87 5857    0   54    5   52   43   10]\n",
      " [   3    7   12    0 5603   15   50   39    8  105]\n",
      " [   5   10   13   35   11 5219   88    2   32    6]\n",
      " [  12    5    7    1   27   27 5825    0   14    0]\n",
      " [   4   11   59   28    7   19    0 6064    5   68]\n",
      " [  16   48   28  214   19  189   43    8 5224   62]\n",
      " [  14    7    8   44  111   75    6  110   54 5520]] \n",
      "\n",
      " [[ 955    0    1    4    2    6    6    1    1    4]\n",
      " [   1 1121    4    2    0    1    4    1    1    0]\n",
      " [   0    0 1006    9    1    1    4    9    1    1]\n",
      " [   0    0   16  972    0    6    0    9    7    0]\n",
      " [   0    1    3    0  934    3   14    3    1   23]\n",
      " [   2    0    2    8    0  860   12    1    7    0]\n",
      " [   7    2    1    0    9    6  930    0    3    0]\n",
      " [   1    6   18    8    0    2    0  984    1    8]\n",
      " [   9    3    2   52    6   31    7    5  853    6]\n",
      " [   4    2    0    4   16    8    1   12   17  945]]\n"
     ]
    }
   ],
   "source": [
    "mnist_lstm_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. CNN\n",
    "* Accuracy: 0.9889\n",
    "* CNN does better than LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 48)        38448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 48)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               307456    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 84)                21588     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 369,174\n",
      "Trainable params: 369,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.1429 - accuracy: 0.9560 - val_loss: 0.0362 - val_accuracy: 0.9889\n",
      "CNN test accuracy: 0.9889000058174133\n",
      "[[5876    0   13    1    0    5   19    0    5    4]\n",
      " [   1 6652   36    0    3    2   22   17    9    0]\n",
      " [   3    5 5924    8    1    1    1   11    2    2]\n",
      " [   1    0   34 6015    0   37    1   24    8   11]\n",
      " [   2    6   12    0 5795    0    7    5    2   13]\n",
      " [   3    1    7   12    0 5347   28    1   14    8]\n",
      " [   4    0    4    1    5    6 5892    0    6    0]\n",
      " [   6    7   34    3    5    1    0 6190    3   16]\n",
      " [   4   10   39    4    7   21   15    3 5733   15]\n",
      " [  18    5   11    7   33   15    1   34   17 5808]] \n",
      "\n",
      " [[ 972    0    0    0    0    1    3    1    3    0]\n",
      " [   0 1125    2    0    0    0    6    1    1    0]\n",
      " [   1    0 1029    0    0    0    0    1    1    0]\n",
      " [   1    0    4  997    0    4    0    3    1    0]\n",
      " [   0    0    3    0  975    0    1    0    0    3]\n",
      " [   2    0    1    6    0  879    2    0    0    2]\n",
      " [   1    1    0    0    2    1  950    0    3    0]\n",
      " [   0    1    6    0    0    0    0 1019    1    1]\n",
      " [   3    0    3    2    0    1    0    1  964    0]\n",
      " [   4    4    0    3    7    5    0    4    3  979]]\n"
     ]
    }
   ],
   "source": [
    "mnist_cnn_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/pecu/FinTech_CommonWealth_Magazine/tree/master/Financial_Innovation/FiancailVision/HW2_ID_%E5%A7%93%E5%90%8D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
